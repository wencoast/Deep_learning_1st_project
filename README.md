# Deep_learning_1st_project
Simple neural network and ResNet performance comparison

## Running Environment

<ul style="list-style: none;">
  
  <li>python 3.6.7</li>
  <li>Tensorflow 1.12.0</li>
  <li>keras 2.1.6-tf</li>

</ul>

## TODO List

<ol>
  
  <li>Comparison of Deep network architectures Simple neural network and ResNet.[Done!]</li>
  <li>Using Momentum optimizer and Adam optimizer with different learning rate.[Done!]</li>
  <li>Using dropout.[Done!]</li>
  <li>Using batch normalization.[Done!]</li>
  <li>Using different activation functions including relu, tanh, leaky_relu, Sigmoid, etc. [Done!] </li>
  <li>Using data augmentation.[Done!]</li>
  <li>Using different optimizers such as ADAGRAD, ADADELTA, ADAM, RMSPROP, MOM. [Done!]</li>
  <li>Using local response normalization.[Done!]</li>
  
</ol>
